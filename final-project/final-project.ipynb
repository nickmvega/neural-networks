{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering Data + Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEED VAE IMPLEMENTATION FROM THIS THATS ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Coordinate shape: torch.Size([784, 34])\n",
      "Coordinate min/max: -1.0 1.0\n",
      "Encoded coordinate shape: torch.Size([784, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 2/3750 [00:00<05:07, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/3750: Loss: 0.161701, Recon: 0.161701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   3%|▎         | 102/3750 [00:08<05:18, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100/3750: Loss: 0.150019, Recon: 0.150019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   5%|▌         | 203/3750 [00:16<03:10, 18.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 200/3750: Loss: 0.173555, Recon: 0.173555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   8%|▊         | 304/3750 [00:21<02:48, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 300/3750: Loss: 0.176901, Recon: 0.176901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  11%|█         | 403/3750 [00:26<02:39, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 400/3750: Loss: 0.158308, Recon: 0.158308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  13%|█▎        | 505/3750 [00:31<02:34, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/3750: Loss: 0.157883, Recon: 0.157883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  16%|█▌        | 604/3750 [00:35<02:37, 20.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 600/3750: Loss: 0.156225, Recon: 0.156225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  19%|█▊        | 702/3750 [00:40<02:30, 20.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 700/3750: Loss: 0.160167, Recon: 0.160167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  21%|██▏       | 805/3750 [00:45<02:36, 18.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 800/3750: Loss: 0.153816, Recon: 0.153816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  24%|██▍       | 904/3750 [00:52<02:57, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 900/3750: Loss: 0.168452, Recon: 0.168452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  27%|██▋       | 1003/3750 [00:57<02:09, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/3750: Loss: 0.163996, Recon: 0.163996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  29%|██▉       | 1104/3750 [01:03<02:35, 16.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1100/3750: Loss: 0.169841, Recon: 0.169841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  32%|███▏      | 1203/3750 [01:09<02:26, 17.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1200/3750: Loss: 0.161970, Recon: 0.161970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  35%|███▍      | 1303/3750 [01:14<02:17, 17.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1300/3750: Loss: 0.165253, Recon: 0.165253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  37%|███▋      | 1405/3750 [01:19<01:49, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1400/3750: Loss: 0.171792, Recon: 0.171792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  40%|████      | 1504/3750 [01:24<01:47, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/3750: Loss: 0.156772, Recon: 0.156772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  43%|████▎     | 1604/3750 [01:29<01:48, 19.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1600/3750: Loss: 0.151292, Recon: 0.151292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  45%|████▌     | 1703/3750 [01:35<01:49, 18.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1700/3750: Loss: 0.166345, Recon: 0.166345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  48%|████▊     | 1805/3750 [01:40<01:35, 20.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1800/3750: Loss: 0.166865, Recon: 0.166865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  51%|█████     | 1903/3750 [01:44<01:28, 20.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1900/3750: Loss: 0.174835, Recon: 0.174835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  53%|█████▎    | 2004/3750 [01:49<01:22, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/3750: Loss: 0.179913, Recon: 0.179913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  56%|█████▌    | 2105/3750 [01:54<01:21, 20.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2100/3750: Loss: 0.169694, Recon: 0.169694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  59%|█████▉    | 2205/3750 [01:59<01:14, 20.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2200/3750: Loss: 0.169520, Recon: 0.169520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  61%|██████▏   | 2304/3750 [02:04<01:09, 20.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2300/3750: Loss: 0.165718, Recon: 0.165718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  64%|██████▍   | 2403/3750 [02:09<01:05, 20.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2400/3750: Loss: 0.167273, Recon: 0.167273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  67%|██████▋   | 2505/3750 [02:14<00:58, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/3750: Loss: 0.168533, Recon: 0.168533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  69%|██████▉   | 2604/3750 [02:18<00:54, 21.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2600/3750: Loss: 0.165044, Recon: 0.165044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  72%|███████▏  | 2703/3750 [02:23<00:49, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2700/3750: Loss: 0.173134, Recon: 0.173134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  75%|███████▍  | 2805/3750 [02:28<00:47, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2800/3750: Loss: 0.164641, Recon: 0.164641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  77%|███████▋  | 2903/3750 [02:33<00:41, 20.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2900/3750: Loss: 0.166172, Recon: 0.166172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  80%|████████  | 3004/3750 [02:38<00:35, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/3750: Loss: 0.152275, Recon: 0.152275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  83%|████████▎ | 3103/3750 [02:43<00:30, 21.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3100/3750: Loss: 0.157655, Recon: 0.157655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  85%|████████▌ | 3205/3750 [02:48<00:25, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3200/3750: Loss: 0.171302, Recon: 0.171302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  88%|████████▊ | 3304/3750 [02:53<00:21, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3300/3750: Loss: 0.160283, Recon: 0.160283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  91%|█████████ | 3404/3750 [02:57<00:17, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3400/3750: Loss: 0.173895, Recon: 0.173895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  93%|█████████▎| 3505/3750 [03:03<00:12, 20.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/3750: Loss: 0.167728, Recon: 0.167728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  96%|█████████▌| 3603/3750 [03:09<00:07, 20.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3600/3750: Loss: 0.170103, Recon: 0.170103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  99%|█████████▉| 3704/3750 [03:15<00:02, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3700/3750: Loss: 0.167345, Recon: 0.167345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 3750/3750 [03:17<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] Loss: 0.164933, Recon: 0.164933, \n",
      "Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 24 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=transform)\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=transform)\n",
    "\n",
    "batch_size = 16  \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
    "\n",
    "def positional_encoding(coords, num_bands=8):\n",
    "    \"\"\"Apply positional encoding to coordinates with multiple frequency bands.\"\"\"\n",
    "    pos_enc = [coords]\n",
    "    for i in range(num_bands):\n",
    "        freq = 2.0 ** i\n",
    "        pos_enc.append(torch.sin(coords * freq * np.pi))\n",
    "        pos_enc.append(torch.cos(coords * freq * np.pi))\n",
    "    return torch.cat(pos_enc, dim=-1)\n",
    "\n",
    "def get_mgrid(sidelen, dim=2, num_bands=8):\n",
    "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.'''\n",
    "    if isinstance(sidelen, int):\n",
    "        sidelen = dim * (sidelen,)\n",
    "    coords = [torch.linspace(-1, 1, s) for s in sidelen]\n",
    "    mesh_coords = torch.meshgrid(*coords, indexing='ij')  \n",
    "    coords = torch.stack(mesh_coords, dim=-1).reshape(-1, dim)\n",
    "    return positional_encoding(coords, num_bands)\n",
    "\n",
    "class SIREN(nn.Module):\n",
    "    def __init__(self, input_dim=2+2*2*8, hidden_dim=256, hidden_layers=3, output_dim=1, first_omega=1.0, hidden_omega=10.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.first_omega = first_omega\n",
    "        self.hidden_omega = hidden_omega\n",
    "\n",
    "        self.first_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            self.first_layer.weight.uniform_(-1/input_dim, 1/input_dim)\n",
    "            self.first_layer.bias.uniform_(-1/input_dim, 1/input_dim)\n",
    "        \n",
    "        self.hidden_layers_list = nn.ModuleList()\n",
    "        for _ in range(hidden_layers):\n",
    "            layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "            with torch.no_grad():\n",
    "\n",
    "                layer.weight.uniform_(-np.sqrt(6/hidden_dim)/hidden_omega, \n",
    "                                      np.sqrt(6/hidden_dim)/hidden_omega)\n",
    "                layer.bias.uniform_(-np.sqrt(6/hidden_dim)/hidden_omega, \n",
    "                                    np.sqrt(6/hidden_dim)/hidden_omega)\n",
    "            self.hidden_layers_list.append(layer)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            self.output_layer.weight.uniform_(-np.sqrt(6/hidden_dim)/hidden_omega, \n",
    "                                              np.sqrt(6/hidden_dim)/hidden_omega)\n",
    "            self.output_layer.bias.uniform_(-1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sin(self.first_omega * self.first_layer(x))\n",
    "        for layer in self.hidden_layers_list:\n",
    "            x = torch.sin(self.hidden_omega * layer(x))\n",
    "\n",
    "        return torch.sigmoid(self.output_layer(x))\n",
    "    \n",
    "    def set_weights_vector(self, weights_vector):\n",
    "        \"\"\"Set all weights from a flattened vector\"\"\"\n",
    "        start_idx = 0\n",
    "        \n",
    "\n",
    "        w_size = self.first_layer.weight.numel()\n",
    "        self.first_layer.weight.data = weights_vector[start_idx:start_idx+w_size].view(self.first_layer.weight.shape)\n",
    "        start_idx += w_size\n",
    "        \n",
    "        b_size = self.first_layer.bias.numel()\n",
    "        self.first_layer.bias.data = weights_vector[start_idx:start_idx+b_size].view(self.first_layer.bias.shape)\n",
    "        start_idx += b_size\n",
    "        \n",
    "\n",
    "        for layer in self.hidden_layers_list:\n",
    "            w_size = layer.weight.numel()\n",
    "            layer.weight.data = weights_vector[start_idx:start_idx+w_size].view(layer.weight.shape)\n",
    "            start_idx += w_size\n",
    "            \n",
    "            b_size = layer.bias.numel()\n",
    "            layer.bias.data = weights_vector[start_idx:start_idx+b_size].view(layer.bias.shape)\n",
    "            start_idx += b_size\n",
    "        \n",
    "\n",
    "        w_size = self.output_layer.weight.numel()\n",
    "        self.output_layer.weight.data = weights_vector[start_idx:start_idx+w_size].view(self.output_layer.weight.shape)\n",
    "        start_idx += w_size\n",
    "        \n",
    "        b_size = self.output_layer.bias.numel()\n",
    "        self.output_layer.bias.data = weights_vector[start_idx:start_idx+b_size].view(self.output_layer.bias.shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calc_total_weights(input_dim, hidden_dim, hidden_layers, output_dim):\n",
    "        \"\"\"Calculate the total number of weights in the SIREN\"\"\"\n",
    "        total = input_dim * hidden_dim + hidden_dim\n",
    "        \n",
    "        total += hidden_layers * (hidden_dim * hidden_dim + hidden_dim)\n",
    "        \n",
    "        total += hidden_dim * output_dim + output_dim\n",
    "        \n",
    "        return total\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_dim=64, siren_config=None):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        # Default SIREN config\n",
    "        self.siren_config = {\n",
    "            'input_dim': 2 + 2*2*8,  \n",
    "            'hidden_dim': 128,       \n",
    "            'hidden_layers': 3,       \n",
    "            'output_dim': 1\n",
    "        }\n",
    "        \n",
    "        # Update config if provided\n",
    "        if siren_config is not None:\n",
    "            self.siren_config.update(siren_config)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, stride=2, padding=1),             # 28x28 -> 14x14\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(32, 64, 4, stride=2, padding=1),            # 14x14 -> 7x7\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 3, stride=1, padding=1),           # 7x7 -> 7x7\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.fc_mu = nn.Linear(512, z_dim)\n",
    "        self.fc_logvar = nn.Linear(512, z_dim)\n",
    "        \n",
    "\n",
    "        total_weights = SIREN.calc_total_weights(\n",
    "            input_dim=self.siren_config['input_dim'],\n",
    "            hidden_dim=self.siren_config['hidden_dim'],\n",
    "            hidden_layers=self.siren_config['hidden_layers'],\n",
    "            output_dim=self.siren_config['output_dim']\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, total_weights) \n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        logvar = torch.clamp(logvar, -4, 4)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    # Modify your VAE's decode method\n",
    "    def decode(self, z):\n",
    "        raw_weights = self.decoder(z)\n",
    "        \n",
    "        # Split and scale weights for different SIREN layers\n",
    "        weights_list = []\n",
    "        start_idx = 0\n",
    "        \n",
    "        # First layer weights - needs uniform(-1/in_dim, 1/in_dim)\n",
    "        in_dim = self.siren_config['input_dim']\n",
    "        first_w_size = in_dim * self.siren_config['hidden_dim']\n",
    "        first_b_size = self.siren_config['hidden_dim']\n",
    "        \n",
    "        first_w = raw_weights[:, start_idx:start_idx+first_w_size].view(-1, self.siren_config['hidden_dim'], in_dim)\n",
    "        start_idx += first_w_size\n",
    "        first_w = torch.tanh(first_w) * (1.0/in_dim)  # Scale to proper range\n",
    "        weights_list.append(first_w.reshape(-1, first_w_size))\n",
    "        \n",
    "        first_b = raw_weights[:, start_idx:start_idx+first_b_size]\n",
    "        start_idx += first_b_size\n",
    "        first_b = torch.tanh(first_b) * (1.0/in_dim)  # Scale to proper range\n",
    "        weights_list.append(first_b)\n",
    "        \n",
    "        # Hidden layers - needs scaled by sqrt(6/hidden_dim)/omega\n",
    "        hidden_dim = self.siren_config['hidden_dim']\n",
    "        hidden_omega = 30.0\n",
    "        scale_factor = np.sqrt(6/hidden_dim)/hidden_omega\n",
    "        \n",
    "        for _ in range(self.siren_config['hidden_layers']):\n",
    "            hidden_w_size = hidden_dim * hidden_dim\n",
    "            hidden_w = raw_weights[:, start_idx:start_idx+hidden_w_size].view(-1, hidden_dim, hidden_dim)\n",
    "            start_idx += hidden_w_size\n",
    "            hidden_w = torch.tanh(hidden_w) * scale_factor\n",
    "            weights_list.append(hidden_w.reshape(-1, hidden_w_size))\n",
    "            \n",
    "            hidden_b_size = hidden_dim\n",
    "            hidden_b = raw_weights[:, start_idx:start_idx+hidden_b_size]\n",
    "            start_idx += hidden_b_size\n",
    "            hidden_b = torch.tanh(hidden_b) * scale_factor\n",
    "            weights_list.append(hidden_b)\n",
    "        \n",
    "        # Output layer\n",
    "        out_dim = self.siren_config['output_dim']\n",
    "        out_w_size = hidden_dim * out_dim\n",
    "        out_w = raw_weights[:, start_idx:start_idx+out_w_size].view(-1, out_dim, hidden_dim)\n",
    "        start_idx += out_w_size\n",
    "        out_w = torch.tanh(out_w) * scale_factor\n",
    "        weights_list.append(out_w.reshape(-1, out_w_size))\n",
    "        \n",
    "        out_b_size = out_dim\n",
    "        out_b = raw_weights[:, start_idx:start_idx+out_b_size]\n",
    "        out_b = torch.tanh(out_b)  # Range (-1, 1) is fine for output bias\n",
    "        weights_list.append(out_b)\n",
    "        \n",
    "        # Concatenate all scaled weights\n",
    "        return torch.cat(weights_list, dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "def train(num_epochs=1, save_interval=1):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "\n",
    "    num_bands = 8\n",
    "    siren_config = {\n",
    "        'input_dim': 2 + 2*2*num_bands,\n",
    "        'hidden_dim': 128, \n",
    "        'hidden_layers': 3, \n",
    "        'output_dim': 1,\n",
    "    }\n",
    "    \n",
    "\n",
    "    vae = VAE(z_dim=64, siren_config=siren_config).to(device) \n",
    "    siren = SIREN(\n",
    "        input_dim=siren_config['input_dim'],\n",
    "        hidden_dim=siren_config['hidden_dim'],\n",
    "        hidden_layers=siren_config['hidden_layers'],\n",
    "        output_dim=siren_config['output_dim']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(vae.parameters(), lr=0.0005)\n",
    "    \n",
    "    coords = get_mgrid(28, num_bands=num_bands).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Coordinate shape:\", coords.shape)\n",
    "        print(\"Coordinate min/max:\", coords[:, 0].min().item(), coords[:, 0].max().item())\n",
    "        print(\"Encoded coordinate shape:\", coords.shape)\n",
    "        \n",
    "        # Visualize the coordinate grid to make sure it's correct\n",
    "        coord_grid = coords[:, :2].reshape(28, 28, 2)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(coord_grid[:, :, 0].cpu())\n",
    "        plt.title(\"X coordinates\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(coord_grid[:, :, 1].cpu())\n",
    "        plt.title(\"Y coordinates\")\n",
    "        plt.savefig(\"coordinate_grid.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    example_data = next(iter(test_loader))\n",
    "    example_images = example_data[0][:8].to(device)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        vae.train()\n",
    "        total_loss = 0\n",
    "        total_recon_loss = 0\n",
    "        total_kl_loss = 0\n",
    "        \n",
    "        for batch_idx, (images, _) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            images = images.to(device)\n",
    "            batch_size = images.size(0)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            siren_weights_batch, mu, logvar = vae(images)\n",
    "            \n",
    "            reconstruction_loss = 0\n",
    "            \n",
    "            reconstructed_images = []\n",
    "            for j in range(batch_size):\n",
    "                siren.set_weights_vector(siren_weights_batch[j])\n",
    "                \n",
    "                reconstructed_image = siren(coords).reshape(1, 1, 28, 28)\n",
    "                reconstructed_images.append(reconstructed_image)\n",
    "            \n",
    "            reconstructed_batch = torch.cat(reconstructed_images, dim=0)\n",
    "            \n",
    "            reconstruction_loss = F.mse_loss(reconstructed_batch, images)\n",
    "            \n",
    "            loss = reconstruction_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(vae.parameters(), max_norm=1.0)\n",
    "            \n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_recon_loss += reconstruction_loss.item()\n",
    "            \n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Batch {batch_idx}/{len(train_loader)}: \"\n",
    "                      f\"Loss: {loss.item():.6f}, \"\n",
    "                      f\"Recon: {reconstruction_loss.item():.6f}\")\n",
    "        \n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_recon = total_recon_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Loss: {avg_loss:.6f}, \"\n",
    "              f\"Recon: {avg_recon:.6f}, \")\n",
    "        \n",
    "\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "\n",
    "            torch.save({\n",
    "                'vae_state_dict': vae.state_dict(),\n",
    "                'siren_config': siren_config,\n",
    "                'epoch': epoch,\n",
    "                'loss': avg_loss\n",
    "            }, 'best_vae_siren_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if epoch % save_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                vae.eval()\n",
    "                \n",
    "\n",
    "                test_recon_images = []\n",
    "                for i in range(example_images.size(0)):\n",
    "                    # Encode and decode\n",
    "                    mu, logvar = vae.encode(example_images[i:i+1])\n",
    "                    z = vae.reparameterize(mu, logvar)\n",
    "                    siren_weights = vae.decode(z)\n",
    "                    \n",
    "                    # Set weights and get reconstruction\n",
    "                    siren.set_weights_vector(siren_weights.squeeze(0))\n",
    "                    recon_image = siren(coords).reshape(1, 28, 28)\n",
    "                    test_recon_images.append(recon_image)\n",
    "                \n",
    "                # Stack the images\n",
    "                test_recon_images = torch.cat(test_recon_images, dim=0)\n",
    "                \n",
    "                # Generate random samples\n",
    "                z = torch.randn(8, vae.z_dim, device=device)\n",
    "                generated_images = []\n",
    "                for i in range(z.size(0)):\n",
    "                    siren_weights = vae.decode(z[i:i+1])\n",
    "                    siren.set_weights_vector(siren_weights.squeeze(0))\n",
    "                    gen_image = siren(coords).reshape(1, 28, 28)\n",
    "                    generated_images.append(gen_image)\n",
    "                \n",
    "\n",
    "                generated_images = torch.cat(generated_images, dim=0)\n",
    "                \n",
    "\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                \n",
    "\n",
    "                for i in range(8):\n",
    "                    plt.subplot(3, 8, i + 1)\n",
    "                    plt.imshow(example_images[i].cpu().squeeze(), cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                    plt.title(\"Original\")\n",
    "                \n",
    "                for i in range(8):\n",
    "                    plt.subplot(3, 8, i + 9)\n",
    "                    plt.imshow(test_recon_images[i].cpu().squeeze(), cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                    plt.title(\"Reconstructed\")\n",
    "                \n",
    "                # Plot generated images\n",
    "                for i in range(8):\n",
    "                    plt.subplot(3, 8, i + 17)\n",
    "                    plt.imshow(generated_images[i].cpu().squeeze(), cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                    plt.title(\"Generated\")\n",
    "                \n",
    "                plt.suptitle(f\"Epoch {epoch+1}\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"vae_siren_epoch_{epoch+1}.png\")\n",
    "                plt.close()\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    return vae, siren\n",
    "\n",
    "def evaluate_model(model_path='best_vae_siren_model.pt'):\n",
    "    # Load model\n",
    "    checkpoint = torch.load(model_path)\n",
    "    siren_config = checkpoint['siren_config']\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    vae = VAE(z_dim=64, siren_config=siren_config).to(device)\n",
    "    vae.load_state_dict(checkpoint['vae_state_dict'])\n",
    "    \n",
    "    siren = SIREN(\n",
    "        input_dim=siren_config['input_dim'],\n",
    "        hidden_dim=siren_config['hidden_dim'],\n",
    "        hidden_layers=siren_config['hidden_layers'],\n",
    "        output_dim=siren_config['output_dim']\n",
    "    ).to(device)\n",
    "    \n",
    "    coords = get_mgrid(28, num_bands=8).to(device)\n",
    "    \n",
    "    example_data = next(iter(test_loader))\n",
    "    test_images = example_data[0][:8].to(device)\n",
    "    test_labels = example_data[1][:8]\n",
    "    \n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed_images = []\n",
    "        for i in range(test_images.size(0)):\n",
    "            mu, logvar = vae.encode(test_images[i:i+1])\n",
    "            z = vae.reparameterize(mu, logvar)\n",
    "            siren_weights = vae.decode(z)\n",
    "            \n",
    "            siren.set_weights_vector(siren_weights.squeeze(0))\n",
    "            recon_image = siren(coords).reshape(1, 28, 28)\n",
    "            reconstructed_images.append(recon_image)\n",
    "        \n",
    "        reconstructed_images = torch.cat(reconstructed_images, dim=0)\n",
    "        \n",
    "        z = torch.randn(8, vae.z_dim, device=device)\n",
    "        generated_images = []\n",
    "        for i in range(z.size(0)):\n",
    "            siren_weights = vae.decode(z[i:i+1])\n",
    "            siren.set_weights_vector(siren_weights.squeeze(0))\n",
    "            gen_image = siren(coords).reshape(1, 28, 28)\n",
    "            generated_images.append(gen_image)\n",
    "        \n",
    "        generated_images = torch.cat(generated_images, dim=0)\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 8, figsize=(16, 6))\n",
    "    \n",
    "    for i in range(8):\n",
    "        # Original\n",
    "        axs[0, i].imshow(test_images[i].cpu().squeeze(), cmap='gray')\n",
    "        axs[0, i].set_title(f\"{class_names[test_labels[i]]}\")\n",
    "        axs[0, i].axis('off')\n",
    "        \n",
    "        # Reconstructed\n",
    "        axs[1, i].imshow(reconstructed_images[i].cpu().squeeze(), cmap='gray')\n",
    "        axs[1, i].set_title(\"Reconstructed\")\n",
    "        axs[1, i].axis('off')\n",
    "        \n",
    "        # Generated\n",
    "        axs[2, i].imshow(generated_images[i].cpu().squeeze(), cmap='gray')\n",
    "        axs[2, i].set_title(\"Generated\")\n",
    "        axs[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"evaluation_results.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return vae, siren\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vae, siren = train(num_epochs=1, save_interval=1)\n",
    "    evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEED TO REDUCE WEIGHTS OUTPUT OF VAE, NEED TOO FIX SIREN INIT, NEED TO FIX OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siren and VAE model (second implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Data Loading \n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=transform)\n",
    "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=transform)\n",
    "\n",
    "batch_size = 16  \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
    "\n",
    "def positional_encoding(coords, num_bands=8):\n",
    "    pos_enc = [coords]\n",
    "    for i in range(num_bands):\n",
    "        freq = 2.0 ** i\n",
    "        pos_enc.append(torch.sin(coords * freq * np.pi))\n",
    "        pos_enc.append(torch.cos(coords * freq * np.pi))\n",
    "    return torch.cat(pos_enc, dim=-1)\n",
    "\n",
    "def get_mgrid(sidelen, dim=2, num_bands=8):\n",
    "    if isinstance(sidelen, int):\n",
    "        sidelen = dim * (sidelen,)\n",
    "    coords = [torch.linspace(-1, 1, s) for s in sidelen]\n",
    "    mesh_coords = torch.meshgrid(*coords, indexing='ij')  \n",
    "    coords = torch.stack(mesh_coords, dim=-1).reshape(-1, dim)\n",
    "    return positional_encoding(coords, num_bands)\n",
    "\n",
    "class SIREN(nn.Module):\n",
    "    def __init__(self, input_dim=2+2*2*8, hidden_dim=256, hidden_layers=3, output_dim=1, first_omega=1.0, hidden_omega=10.0):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.first_omega = first_omega\n",
    "        self.hidden_omega = hidden_omega\n",
    "\n",
    "        self.first_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        with torch.no_grad():\n",
    "            self.first_layer.weight.uniform_(-1/input_dim, 1/input_dim)\n",
    "            self.first_layer.bias.uniform_(-1/input_dim, 1/input_dim)\n",
    "        \n",
    "        self.hidden_layers_list = nn.ModuleList()\n",
    "        for _ in range(hidden_layers):\n",
    "            layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "            with torch.no_grad():\n",
    "                layer.weight.uniform_(-np.sqrt(6/hidden_dim)/hidden_omega, \n",
    "                                      np.sqrt(6/hidden_dim)/hidden_omega)\n",
    "                layer.bias.uniform_(-np.sqrt(6/hidden_dim)/hidden_omega, \n",
    "                                    np.sqrt(6/hidden_dim)/hidden_omega)\n",
    "            self.hidden_layers_list.append(layer)\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        with torch.no_grad():\n",
    "            self.output_layer.weight.uniform_(-np.sqrt(6/hidden_dim)/hidden_omega, \n",
    "                                              np.sqrt(6/hidden_dim)/hidden_omega)\n",
    "            self.output_layer.bias.uniform_(-1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.sin(self.first_omega * self.first_layer(x))\n",
    "        for layer in self.hidden_layers_list:\n",
    "            x = torch.sin(self.hidden_omega * layer(x))\n",
    "\n",
    "        return torch.sigmoid(self.output_layer(x))\n",
    "    \n",
    "    def set_weights_vector(self, weights_vector):\n",
    "        \"\"\"Set all weights from a flattened vector\"\"\"\n",
    "        start_idx = 0\n",
    "        \n",
    "        w_size = self.first_layer.weight.numel()\n",
    "        self.first_layer.weight.data = weights_vector[start_idx:start_idx+w_size].view(self.first_layer.weight.shape)\n",
    "        start_idx += w_size\n",
    "        \n",
    "        b_size = self.first_layer.bias.numel()\n",
    "        self.first_layer.bias.data = weights_vector[start_idx:start_idx+b_size].view(self.first_layer.bias.shape)\n",
    "        start_idx += b_size\n",
    "        \n",
    "        for layer in self.hidden_layers_list:\n",
    "            w_size = layer.weight.numel()\n",
    "            layer.weight.data = weights_vector[start_idx:start_idx+w_size].view(layer.weight.shape)\n",
    "            start_idx += w_size\n",
    "            \n",
    "            b_size = layer.bias.numel()\n",
    "            layer.bias.data = weights_vector[start_idx:start_idx+b_size].view(layer.bias.shape)\n",
    "            start_idx += b_size\n",
    "        \n",
    "        w_size = self.output_layer.weight.numel()\n",
    "        self.output_layer.weight.data = weights_vector[start_idx:start_idx+w_size].view(self.output_layer.weight.shape)\n",
    "        start_idx += w_size\n",
    "        \n",
    "        b_size = self.output_layer.bias.numel()\n",
    "        self.output_layer.bias.data = weights_vector[start_idx:start_idx+b_size].view(self.output_layer.bias.shape)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calc_total_weights(input_dim, hidden_dim, hidden_layers, output_dim):\n",
    "        \"\"\"Calculate the total number of weights in the SIREN\"\"\"\n",
    "        total = input_dim * hidden_dim + hidden_dim  # First layer\n",
    "        total += hidden_layers * (hidden_dim * hidden_dim + hidden_dim)  # Hidden layers\n",
    "        total += hidden_dim * output_dim + output_dim  # Output layer\n",
    "        return total\n",
    "\n",
    "    def get_weights_vector(self):\n",
    "        \"\"\"Get all weights as a flattened vector\"\"\"\n",
    "        weights = []\n",
    "        weights.append(self.first_layer.weight.data.flatten())\n",
    "        weights.append(self.first_layer.bias.data.flatten())\n",
    "        \n",
    "        for layer in self.hidden_layers_list:\n",
    "            weights.append(layer.weight.data.flatten())\n",
    "            weights.append(layer.bias.data.flatten())\n",
    "        \n",
    "        weights.append(self.output_layer.weight.data.flatten())\n",
    "        weights.append(self.output_layer.bias.data.flatten())\n",
    "        \n",
    "        return torch.cat(weights, dim=0)\n",
    "\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, siren_config=None):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.siren_config = {\n",
    "            'input_dim': 2 + 2*2*8,\n",
    "            'hidden_dim': 128,\n",
    "            'hidden_layers': 3,\n",
    "            'output_dim': 1\n",
    "        }\n",
    "        \n",
    "        if siren_config is not None:\n",
    "            self.siren_config.update(siren_config)\n",
    "        \n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 28 * 28),\n",
    "            nn.Tanh()\n",
    "            #nn.Unflatten(1, (128, 7, 7)),\n",
    "            #nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.generator(z)\n",
    "        return x.view(-1, 1, 28, 28)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.discriminator(x)\n",
    "\n",
    "# GAN Class (Main Model)\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, z_dim=100):\n",
    "        super(GAN, self).__init__()\n",
    "\n",
    "        self.generator = Generator(z_dim=z_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "    def forward(self, z):\n",
    "        generated_image = self.generator(z)\n",
    "        return generated_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, z_dim=64, siren_config=None):\n",
    "#         super().__init__()\n",
    "#         self.z_dim = z_dim\n",
    "        \n",
    "#         self.siren_config = {\n",
    "#             'input_dim': 2 + 2*2*8,  \n",
    "#             'hidden_dim': 128,       \n",
    "#             'hidden_layers': 3,       \n",
    "#             'output_dim': 1\n",
    "#         }\n",
    "        \n",
    "#         if siren_config is not None:\n",
    "#             self.siren_config.update(siren_config)\n",
    "        \n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, 4, stride=2, padding=1),             # 28x28 -> 14x14\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(32, 64, 4, stride=2, padding=1),            # 14x14 -> 7x7\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64, 128, 3, stride=1, padding=1),           # 7x7 -> 7x7\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(128 * 7 * 7, 512),\n",
    "#             nn.LeakyReLU(0.2, inplace=True)\n",
    "#         )\n",
    "        \n",
    "#         self.fc_mu = nn.Linear(512, z_dim)\n",
    "#         self.fc_logvar = nn.Linear(512, z_dim)\n",
    "        \n",
    "#         total_weights = SIREN.calc_total_weights(\n",
    "#             input_dim=self.siren_config['input_dim'],\n",
    "#             hidden_dim=self.siren_config['hidden_dim'],\n",
    "#             hidden_layers=self.siren_config['hidden_layers'],\n",
    "#             output_dim=self.siren_config['output_dim']\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(z_dim, 512),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Linear(512, 1024),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Linear(1024, total_weights) \n",
    "#         )\n",
    "    \n",
    "#     def encode(self, x):\n",
    "#         h = self.encoder(x)\n",
    "#         return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "#     def reparameterize(self, mu, logvar):\n",
    "#         logvar = torch.clamp(logvar, -4, 4)\n",
    "#         std = torch.exp(0.5 * logvar)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         return mu + eps * std\n",
    "    \n",
    "#     def decode(self, z):\n",
    "#         return self.decoder(z)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         mu, logvar = self.encode(x)\n",
    "#         z = self.reparameterize(mu, logvar)\n",
    "#         return self.decode(z), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/3750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 3750/3750 [01:02<00:00, 60.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 625/625 [00:02<00:00, 240.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.2114\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x1 and 100x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 191\u001b[0m\n\u001b[1;32m    189\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_loader))\n\u001b[1;32m    190\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 191\u001b[0m weights_vector_batch, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m reconstructions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    193\u001b[0m batch_size_local \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 191\u001b[0m, in \u001b[0;36mGAN.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[0;32m--> 191\u001b[0m     generated_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generated_image\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 160\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, z):\n\u001b[0;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x1 and 100x256)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gan = GAN(z_dim=100).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer_g = optim.Adam(gan.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(gan.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Create the grid (same as before)\n",
    "grid = get_mgrid(28, dim=2, num_bands=8).to(device)  \n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 1\n",
    "gan.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for real_images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # Create labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train the Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # Forward pass for real images\n",
    "        real_output = gan.discriminator(real_images)\n",
    "        real_loss = criterion(real_output, real_labels)\n",
    "\n",
    "        # Generate fake images\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "        fake_images = gan.generator(z)\n",
    "\n",
    "        # Forward pass for fake images\n",
    "        fake_output = gan.discriminator(fake_images.detach())  # Detach to avoid backprop through the generator\n",
    "        fake_loss = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # Combine real and fake losses\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train the Generator\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        # Forward pass for fake images (again, but this time calculate for generator's loss)\n",
    "        fake_output = gan.discriminator(fake_images)\n",
    "        g_loss = criterion(fake_output, real_labels)  # We want the generator to fool the discriminator\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Update total train loss\n",
    "        train_loss += d_loss.item() + g_loss.item()\n",
    "\n",
    "    # Print loss for this epoch\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f}\")\n",
    "\n",
    "# Testing Loop\n",
    "gan.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        # Labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Forward pass for real images\n",
    "        real_output = gan.discriminator(images)\n",
    "        real_loss = criterion(real_output, real_labels)\n",
    "\n",
    "        # Generate fake images\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "        fake_images = gan.generator(z)\n",
    "\n",
    "        # Forward pass for fake images\n",
    "        fake_output = gan.discriminator(fake_images)\n",
    "        fake_loss = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # Combine real and fake losses\n",
    "        d_loss = real_loss + fake_loss\n",
    "\n",
    "        # Update total test loss\n",
    "        test_loss += d_loss.item() * batch_size\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# vae = VAE(z_dim=64).to(device)\n",
    "\n",
    "# siren = SIREN(input_dim=vae.siren_config['input_dim'],\n",
    "#             hidden_dim=vae.siren_config['hidden_dim'],\n",
    "#             hidden_layers=vae.siren_config['hidden_layers'],\n",
    "#             output_dim=vae.siren_config['output_dim']).to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# bce_loss = nn.BCELoss()\n",
    "\n",
    "# grid = get_mgrid(28, dim=2, num_bands=8).to(device)  \n",
    "\n",
    "# num_epochs = 1\n",
    "# vae.train()\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = 0.0\n",
    "#     for images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "#         images = images.to(device)   # images shape: (batch, 1, 28, 28)\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         weights_vector_batch, mu, logvar = vae(images)\n",
    "        \n",
    "#         reconstructions = []\n",
    "#         batch_size_local = images.shape[0]\n",
    "#         for i in range(batch_size_local):\n",
    "#             with torch.no_grad():\n",
    "#                 siren.set_weights_vector(weights_vector_batch[i])\n",
    "#             rec = siren(grid) \n",
    "#             rec = rec.view(1, 28, 28) \n",
    "#             reconstructions.append(rec)\n",
    "\n",
    "#         reconstructions = torch.cat(reconstructions, dim=0)\n",
    "\n",
    "#         rec_loss = bce_loss(reconstructions, images.squeeze(1))\n",
    "\n",
    "#         kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        \n",
    "#         loss = rec_loss + kl_loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         train_loss += loss.item() * batch_size_local\n",
    "        \n",
    "#     train_loss /= len(train_loader.dataset)\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f}\")\n",
    "\n",
    "# vae.eval()\n",
    "# test_loss = 0.0\n",
    "# with torch.no_grad():\n",
    "#     for images, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "#         images = images.to(device)\n",
    "#         weights_vector_batch, mu, logvar = vae(images)\n",
    "#         reconstructions = []\n",
    "#         batch_size_local = images.shape[0]\n",
    "#         for i in range(batch_size_local):\n",
    "#             siren.set_weights_vector(weights_vector_batch[i])\n",
    "#             rec = siren(grid)  # output shape: (28*28, 1)\n",
    "#             rec = rec.view(1, 28, 28)\n",
    "#             reconstructions.append(rec)\n",
    "#         reconstructions = torch.cat(reconstructions, dim=0)\n",
    "#         rec_loss = bce_loss(reconstructions, images.squeeze(1))\n",
    "#         kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "#         loss = rec_loss + kl_loss\n",
    "#         test_loss += loss.item() * batch_size_local\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# # Visualize some reconstructed images.\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# vae.eval()\n",
    "# with torch.no_grad():\n",
    "    # images, labels = next(iter(test_loader))\n",
    "    # images = images.to(device)\n",
    "    # weights_vector_batch, _, _ = vae(images)\n",
    "    # reconstructions = []\n",
    "    # batch_size_local = images.shape[0]\n",
    "    # for i in range(batch_size_local):\n",
    "    #     siren.set_weights_vector(weights_vector_batch[i])\n",
    "    #     rec = siren(grid)\n",
    "    #     rec = rec.view(28, 28)\n",
    "    #     reconstructions.append(rec.cpu().numpy())\n",
    "\n",
    "gan.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels = next(iter(test_loader))\n",
    "    images = images.to(device)\n",
    "    weights_vector_batch, _, _ = gan(real_output)\n",
    "    reconstructions = []\n",
    "    batch_size_local = images.shape[0]\n",
    "    for i in range(batch_size_local):\n",
    "        siren.set_weights_vector(weights_vector_batch[i])\n",
    "        rec = siren(grid)\n",
    "        rec = rec.view(28, 28)\n",
    "        reconstructions.append(rec.cpu().numpy())\n",
    "    # z = torch.randn(16, 100).to(device)  # Generate 16 random latent vectors\n",
    "    # fake_images = gan.generator(z)\n",
    "\n",
    "    # # Rescale and display the generated images\n",
    "    # fake_images = fake_images.cpu().detach()\n",
    "    # grid_img = torchvision.utils.make_grid(fake_images, nrow=4, normalize=True)\n",
    "    # plt.imshow(grid_img.permute(1, 2, 0))  # Convert to HWC format\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "num_examples = 6\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(num_examples):\n",
    "\n",
    "    plt.subplot(2, num_examples, i+1)\n",
    "    plt.imshow(images[i].cpu().squeeze(0), cmap=\"gray\")\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(2, num_examples, num_examples+i+1)\n",
    "    plt.imshow(reconstructions[i], cmap=\"gray\")\n",
    "    plt.title(\"Reconstruction\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 3750/3750 [00:27<00:00, 135.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Loss: 0.1346\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_examples):\n\u001b[32m     83\u001b[39m     plt.subplot(\u001b[32m2\u001b[39m, num_examples, num_examples + i + \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgray\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     plt.title(\u001b[33m\"\u001b[39m\u001b[33mGenerated\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m     plt.axis(\u001b[33m\"\u001b[39m\u001b[33moff\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/neural-networks/myenv/lib/python3.11/site-packages/matplotlib/pyplot.py:3590\u001b[39m, in \u001b[36mimshow\u001b[39m\u001b[34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[39m\n\u001b[32m   3568\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.imshow)\n\u001b[32m   3569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimshow\u001b[39m(\n\u001b[32m   3570\u001b[39m     X: ArrayLike | PIL.Image.Image,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3588\u001b[39m     **kwargs,\n\u001b[32m   3589\u001b[39m ) -> AxesImage:\n\u001b[32m-> \u001b[39m\u001b[32m3590\u001b[39m     __ret = \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3594\u001b[39m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[43m=\u001b[49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3595\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3596\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3597\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3598\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3599\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3600\u001b[39m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3602\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3606\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3607\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3608\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3610\u001b[39m     sci(__ret)\n\u001b[32m   3611\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/neural-networks/myenv/lib/python3.11/site-packages/matplotlib/__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/neural-networks/myenv/lib/python3.11/site-packages/matplotlib/axes/_axes.py:5976\u001b[39m, in \u001b[36mAxes.imshow\u001b[39m\u001b[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[39m\n\u001b[32m   5973\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5974\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_aspect(aspect)\n\u001b[32m-> \u001b[39m\u001b[32m5976\u001b[39m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5977\u001b[39m im.set_alpha(alpha)\n\u001b[32m   5978\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5979\u001b[39m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/neural-networks/myenv/lib/python3.11/site-packages/matplotlib/image.py:685\u001b[39m, in \u001b[36m_ImageBase.set_data\u001b[39m\u001b[34m(self, A)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL.Image.Image):\n\u001b[32m    684\u001b[39m     A = pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28mself\u001b[39m._A = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._imcache = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/neural-networks/myenv/lib/python3.11/site-packages/matplotlib/image.py:646\u001b[39m, in \u001b[36m_ImageBase._normalize_image_array\u001b[39m\u001b[34m(A)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_normalize_image_array\u001b[39m(A):\n\u001b[32m    642\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    643\u001b[39m \u001b[33;03m    Check validity of image-like input *A* and normalize it to a format suitable for\u001b[39;00m\n\u001b[32m    644\u001b[39m \u001b[33;03m    Image subclasses.\u001b[39;00m\n\u001b[32m    645\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m     A = \u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_masked_invalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m A.dtype != np.uint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.can_cast(A.dtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msame_kind\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    648\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m                         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconverted to float\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/neural-networks/myenv/lib/python3.11/site-packages/matplotlib/cbook.py:684\u001b[39m, in \u001b[36msafe_masked_invalid\u001b[39m\u001b[34m(x, copy)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msafe_masked_invalid\u001b[39m(x, copy=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m     x = np.array(x, subok=\u001b[38;5;28;01mTrue\u001b[39;00m, copy=copy)\n\u001b[32m    685\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x.dtype.isnative:\n\u001b[32m    686\u001b[39m         \u001b[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001b[39;00m\n\u001b[32m    687\u001b[39m         \u001b[38;5;66;03m# copy with the byte order swapped.\u001b[39;00m\n\u001b[32m    688\u001b[39m         \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n\u001b[32m    689\u001b[39m         x = x.byteswap(inplace=copy).view(x.dtype.newbyteorder(\u001b[33m'\u001b[39m\u001b[33mN\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/neural-networks/myenv/lib/python3.11/site-packages/torch/_tensor.py:1194\u001b[39m, in \u001b[36mTensor.__array__\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1194\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.numpy().astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gan = GAN(z_dim=100).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer_g = optim.Adam(gan.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(gan.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Create the grid (same as before)\n",
    "grid = get_mgrid(28, dim=2, num_bands=8).to(device)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 1\n",
    "gan.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    for real_images, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # Create labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Train the Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # Forward pass for real images\n",
    "        real_output = gan.discriminator(real_images)\n",
    "        real_loss = criterion(real_output, real_labels)\n",
    "\n",
    "        # Generate fake images\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "        fake_images = gan.generator(z)\n",
    "\n",
    "        # Forward pass for fake images\n",
    "        fake_output = gan.discriminator(fake_images.detach())  # Detach to avoid backprop through the generator\n",
    "        fake_loss = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # Combine real and fake losses\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Train the Generator\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        # Forward pass for fake images (again, but this time calculate for generator's loss)\n",
    "        fake_output = gan.discriminator(fake_images)\n",
    "        g_loss = criterion(fake_output, real_labels)  # We want the generator to fool the discriminator\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Update total train loss\n",
    "        train_loss += d_loss.item() + g_loss.item()\n",
    "\n",
    "    # Print loss for this epoch\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Visualizing images every epoch (you can adjust to every few batches if needed)\n",
    "    if epoch % 1 == 0:  # Adjust for every epoch\n",
    "        num_examples = 6\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Plot real images\n",
    "        for i in range(num_examples):\n",
    "            plt.subplot(2, num_examples, i+1)\n",
    "            plt.imshow(real_images[i].cpu().squeeze(0), cmap=\"gray\")\n",
    "            plt.title(\"Real\")\n",
    "            plt.axis(\"off\")\n",
    "        \n",
    "        # Plot generated (fake) images\n",
    "        for i in range(num_examples):\n",
    "            plt.subplot(2, num_examples, num_examples + i + 1)\n",
    "            plt.imshow(fake_images[i].cpu().squeeze(0), cmap=\"gray\")\n",
    "            plt.title(\"Generated\")\n",
    "            plt.axis(\"off\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Testing Loop\n",
    "gan.eval()\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        # Labels for real and fake images\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # Forward pass for real images\n",
    "        real_output = gan.discriminator(images)\n",
    "        real_loss = criterion(real_output, real_labels)\n",
    "\n",
    "        # Generate fake images\n",
    "        z = torch.randn(batch_size, 100).to(device)\n",
    "        fake_images = gan.generator(z)\n",
    "\n",
    "        # Forward pass for fake images\n",
    "        fake_output = gan.discriminator(fake_images)\n",
    "        fake_loss = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # Combine real and fake losses\n",
    "        d_loss = real_loss + fake_loss\n",
    "\n",
    "        # Update total test loss\n",
    "        test_loss += d_loss.item() * batch_size\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# After training, visualize some generated images\n",
    "num_examples = 6\n",
    "z = torch.randn(num_examples, 100).to(device)  # Generate random latent vectors\n",
    "generated_images = gan.generator(z)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(num_examples):\n",
    "    plt.subplot(2, num_examples, num_examples + i + 1)\n",
    "    plt.imshow(fake_images[i].detach().cpu().squeeze(0).numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Generated\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(num_examples):\n",
    "    plt.subplot(2, num_examples, num_examples + i + 1)\n",
    "    plt.imshow(fake_images[i].detach().cpu().squeeze(0).numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Generated\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
