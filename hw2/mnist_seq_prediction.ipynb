{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c957f179",
      "metadata": {
        "id": "c957f179"
      },
      "source": [
        "## Part II: CNN-LSTM for Sequence Prediction\n",
        "### Introduction:\n",
        "\n",
        "- In this section, you will extend the CNN from section (1) to a hybrid CNN-LSTM model to predict the future elements of a sequence.\n",
        "- Instead of providing a single digit image to predict its category, you will be given a sequence of digit images. These sequences follow a pattern in that each consecutive image pair will be shifted by some constant amount. You will design a CNN-LSTM model to recognize those patterns from raw images and predict the future digits.\n",
        "- For instance, the input and target of the CNN-LSTM model can be the image squence whose categories are shown as below: \n",
        "            Input: 1,3,5,7,9,1   Target: 3,5,7  (shifted by 2)\n",
        "            Input: 2,6,0,4,8,2   Target: 6,0,4  (shifted by 4)\n",
        "where the input and target consists of 5 elements and 3 elements, respectively.\n",
        "- The training sequences are generated by varying shifts.  We will also include some unseen shifts in test sequences to validate the model's generalization ability.\n",
        "\n",
        "### Task:\n",
        "- You need to design the model and complete the training loop with Pytorch.\n",
        "- You need to achieve 93% averaged Top1 Acc on test data.\n",
        "- This experiment shares the same dataset with the first section. Once you prepare the data following the first section, you do not need to download extra content. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "14e6af01",
      "metadata": {
        "id": "14e6af01"
      },
      "outputs": [],
      "source": [
        "# The arguments of the experiment\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        # Based on the availablity of GPU, decide whether to run the experiment on cuda or cpu.\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # The random seed for the exp.\n",
        "        self.seed = 1\n",
        "        # The mini batch size of training and testing data. If you find you machines run very slow \n",
        "        # or experinece with OOM issue, you can set a smaller batch size\n",
        "        self.batch_size = 50\n",
        "        # The epochs of the exps. The referenced model achieve over 95% test accuracy after 1 epoch.\n",
        "        self.epochs = 1\n",
        "        # The learning rate of the SGD optimizer\n",
        "        self.lr = 0.1\n",
        "        # The momentum of SGD optimizer\n",
        "        self.momentum = 0.5\n",
        "        # how many iterations to display the training stats\n",
        "        self.log_interval = 10\n",
        "        # The height of input image\n",
        "        self.img_h = 28\n",
        "        # The width of the input image\n",
        "        self.img_w = 28\n",
        "        # The length of input sequence\n",
        "        self.input_seq_len = 5\n",
        "        # The lenght of the sequence to predict\n",
        "        self.target_seq_len = 2\n",
        "        # The list to sample shift to generate the training sequence.\n",
        "        self.train_shift_list = [1,2,4,5]\n",
        "        # The list to sample shift to generate the testing sequence. \n",
        "        self.test_shift_list = [1,2,3,4,5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "79b9552c-9f53-4a5e-97d9-3b3c8c5c817a",
      "metadata": {
        "id": "79b9552c-9f53-4a5e-97d9-3b3c8c5c817a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c36c7916750>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pytorch mnist cnn + lstm\n",
        "# Load necessary library\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset \n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt \n",
        "args = Args()\n",
        "torch.manual_seed(args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d87a29",
      "metadata": {
        "id": "71d87a29"
      },
      "source": [
        "### 0. The dataloader\n",
        "- Load the data from csv file\n",
        "- Generate the input and target image sequences spaced by constant distance sampled from the predefined shift list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "713c2177-153d-446b-ae15-9489c0bba936",
      "metadata": {
        "id": "713c2177-153d-446b-ae15-9489c0bba936"
      },
      "outputs": [],
      "source": [
        "# The dataset to generated training and testing sequence\n",
        "class MNIST_SEQ_DATASET(Dataset):\n",
        "    def __init__(self, csv_path, height, width, input_len, output_len, seq_shift, transform=None):\n",
        "        \"\"\"\n",
        "        Custom dataset example for reading data from csv\n",
        "\n",
        "        Args:\n",
        "            csv_path (string): path to csv file\n",
        "            height (int): image height\n",
        "            width (int): image width\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.labels = np.asarray(self.data.iloc[:, 0])\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.input_len = input_len\n",
        "        self.output_len = output_len\n",
        "        self.transform = transform\n",
        "        self.seq_shift = seq_shift\n",
        "        unique_label_array = np.unique(self.labels)\n",
        "        self.label_data_id_dict = {}\n",
        "        for unique_label in unique_label_array:\n",
        "            self.label_data_id_dict[unique_label] = np.where(self.labels == unique_label)[0]   \n",
        "        \n",
        "    def get_single_image(self, index):\n",
        "        single_image_label = self.labels[index]\n",
        "        # Read each 784 pixels and reshape the 1D array ([784]) to 2D array ([28,28])\n",
        "        img_as_np = np.asarray(self.data.iloc[index][1:]).reshape(28, 28).astype('uint8')\n",
        "        # Convert image from numpy array to PIL image, mode 'L' is for grayscale\n",
        "        img_as_img = Image.fromarray(img_as_np)\n",
        "        img_as_img = img_as_img.convert('L')\n",
        "        # Transform image to tensor\n",
        "        if self.transform is not None:\n",
        "            img_as_tensor = self.transform(img_as_img)\n",
        "        # Return image and the label\n",
        "        return (img_as_tensor, single_image_label)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Randomly sample the shift from predefined shift list\n",
        "        seq_shift = np.random.choice(self.seq_shift)\n",
        "        # Randomly select one category as leading digit\n",
        "        start_idx = np.random.choice(10)\n",
        "        # The sequence with following digits\n",
        "        seq_digit = np.arange(start_idx, start_idx + seq_shift * (self.input_len + self.output_len), seq_shift)\n",
        "        # Modulo opeartion over the digit sequence\n",
        "        seq_digit = seq_digit % 10\n",
        "        img_seq = []\n",
        "        label_seq = []\n",
        "        # Collect the images for each digit\n",
        "        for digit in seq_digit:\n",
        "            data_id = np.random.choice(self.label_data_id_dict[digit])\n",
        "            img, label = self.get_single_image(data_id)\n",
        "            img_seq.append(img)\n",
        "            label_seq.append(label)\n",
        "        # Return image and the label\n",
        "        input_img_seq = img_seq[:self.input_len]\n",
        "        input_label_seq = label_seq[:self.input_len]\n",
        "        target_img_seq = img_seq[self.input_len:]\n",
        "        target_label_seq = label_seq[self.input_len:]\n",
        "        return torch.stack(input_img_seq), torch.stack(target_img_seq), \\\n",
        "                torch.from_numpy(np.stack(input_label_seq)), \\\n",
        "                torch.from_numpy(np.stack(target_label_seq)), \\\n",
        "                seq_shift\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "d9e8b05a",
      "metadata": {
        "id": "d9e8b05a"
      },
      "outputs": [],
      "source": [
        "# Instantiate the dataset which is then wrapperd by the DataLoader for effective prefecting\n",
        "transformations = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_train = \\\n",
        "    MNIST_SEQ_DATASET('./mnist_train.csv',\n",
        "                             args.img_h, args.img_w, args.input_seq_len, args.target_seq_len,\n",
        "                             args.test_shift_list,\n",
        "                             transformations)\n",
        "\n",
        "mnist_test = \\\n",
        "    MNIST_SEQ_DATASET('./mnist_test.csv',\n",
        "                             args.img_h, args.img_w, args.input_seq_len, args.target_seq_len,\n",
        "                             args.test_shift_list,\n",
        "                             transformations)\n",
        "\n",
        "mnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                                    batch_size=args.batch_size,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
        "                                                    batch_size=args.batch_size,\n",
        "                                                    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "354edd11",
      "metadata": {
        "id": "354edd11",
        "outputId": "3590efd7-a726-4deb-bf4c-89e9bb3ed412"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the input sequence and target sequence\n",
        "input_img_seq, target_img_seq, input_label_seq, target_label_seq, seq_shift = mnist_train[0]\n",
        "img_to_disp = input_img_seq.permute(1,2,0,3).reshape(args.img_h,-1,args.img_w)\n",
        "input_img_seq = img_to_disp.reshape(args.img_h, -1)\n",
        "img_to_disp = target_img_seq.permute(1,2,0,3).reshape(args.img_h,-1,args.img_w)\n",
        "target_img_seq = img_to_disp.reshape(args.img_h, -1)\n",
        "plt.imshow(input_img_seq,  cmap=\"gray\")\n",
        "plt.title('input sequence shifed by {}'.format(seq_shift))\n",
        "plt.show()\n",
        "plt.imshow(target_img_seq, cmap=\"gray\")\n",
        "plt.title('target sequence shifed by {}'.format(seq_shift))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd654469",
      "metadata": {
        "id": "cd654469"
      },
      "source": [
        "### 1. (TODO) The CNN-LSTM Model [20 points]\n",
        "- Complete the following section to create a CNN-LSTM model for the sequence prediction problem. \n",
        "- You can borrow the CNN design from previous section as the CNN encodes the categorical features of the image\n",
        "- The CNN-LSTM should consist of the three modules: \n",
        "    - CNN for extracting visual features to a single feature vector\n",
        "    - LSTM taking as input the sequence of feature vectors from CNN and producing a hidden state suitable to predict the next element\n",
        "    - A decoder to convert the LSTM hidden state to a categorical prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "879a59ad",
      "metadata": {
        "id": "879a59ad"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"Custom CNN model to extract visual features from input image\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\" Define and instantiate your layers\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(800, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\" \n",
        "        Run forward pass on input image X\n",
        "        \n",
        "        Args:\n",
        "            x: torch tensor of input image, \n",
        "                with shape of [batch_size, 1, img_h, img_w]\n",
        "        \n",
        "        Return:\n",
        "            out: torch tensor of feature vector computed on input image, \n",
        "                with shape of [batch_size, latent_dim]\n",
        "         \n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        # x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        # x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = x.view(-1, 800)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    \"\"\" Custom CNN-LSTM model for sequence prediction problem \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\" Define and instantiate your layers\"\"\"\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        # YOUR CODE HERE\n",
        "        self.cnn = CNN()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=10, hidden_size=128, num_layers=1, batch_first=True)\n",
        "\n",
        "        self.decoder = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "    def forward(self, x, num_step_to_predict):\n",
        "        \"\"\" \n",
        "        Run forward pass on image squence x and predict the future digits\n",
        "        \n",
        "        Args:\n",
        "            x : torch tensor of input image sequence, \n",
        "                    with shape of [batch_size, input_time_step, 1, img_h, img_w]\n",
        "            num_step_to_predict: an interger on how many steps to predict. \n",
        "            \n",
        "        Returns:\n",
        "            output: torch tensor of predicted categorical distribution  \n",
        "                    for the ENTIRE sequence, including input and predicted sequence, \n",
        "                    with shape of [batch_size, input_time_step + num_step_to_predict, 10].\n",
        "                    Noted the output from i step is the prediction for 1+1 step. \n",
        "            \n",
        "        \"\"\"\n",
        "        batch_size, input_time_step = x.size(0), x.size(1)\n",
        "\n",
        "        x = x.view(batch_size * input_time_step, 1, x.size(3), x.size(4))\n",
        "\n",
        "        cnn = self.cnn(x)\n",
        "        cnn = cnn.view(batch_size, input_time_step, -1)\n",
        "\n",
        "        output_lstm, (h_n, c_n) = self.lstm(cnn)\n",
        "        output_decoder = self.decoder(output_lstm)\n",
        "\n",
        "        curr_output = output_lstm[:, -1:, :]\n",
        "        curr_decoder = self.decoder(curr_output)\n",
        "\n",
        "        pred_i = []\n",
        "        for _ in range(num_step_to_predict):\n",
        "            predicted_seq, (h_n, c_n) = self.lstm(curr_decoder, (h_n, c_n))\n",
        "            curr_output = predicted_seq\n",
        "            curr_decoder = self.decoder(predicted_seq)\n",
        "            pred_i.append(curr_decoder)\n",
        "\n",
        "        return torch.cat([output_decoder, torch.cat(pred_i, dim=1)], dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ee3154",
      "metadata": {
        "id": "36ee3154"
      },
      "source": [
        "### 2. (TODO) The Training Loop [15 points]\n",
        "- Instantiate the model and optimizer\n",
        "- Select proper loss function for this task\n",
        "- Complete the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "064084e1-ac41-4e84-a666-a3446b69fe9a",
      "metadata": {
        "id": "064084e1-ac41-4e84-a666-a3446b69fe9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: [0/1200 (0%)], Loss: 2.30734\n",
            "Train: [100/1200 (8%)], Loss: 2.10071\n",
            "Train: [200/1200 (17%)], Loss: 1.89073\n",
            "Train: [300/1200 (25%)], Loss: 1.01242\n",
            "Train: [400/1200 (33%)], Loss: 0.51442\n",
            "Train: [500/1200 (42%)], Loss: 0.15871\n",
            "Train: [600/1200 (50%)], Loss: 0.11781\n",
            "Train: [700/1200 (58%)], Loss: 0.03676\n",
            "Train: [800/1200 (67%)], Loss: 0.06123\n",
            "Train: [900/1200 (75%)], Loss: 0.03822\n",
            "Train: [1000/1200 (83%)], Loss: 0.02923\n",
            "Train: [1100/1200 (92%)], Loss: 0.10899\n"
          ]
        }
      ],
      "source": [
        "model = CNN_LSTM()\n",
        "model = model.to(args.device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (input_img_seq, target_img_seq, input_label_seq, target_label_seq, seq_shift) in enumerate(mnist_train_loader):\n",
        "        # batch_size * input_seq_len * 1 * img_h * img_w\n",
        "        input_img_seq = input_img_seq.to(args.device)\n",
        "        # batch_size * input_seq_len\n",
        "        input_label_seq = input_label_seq.to(args.device)\n",
        "        # batch_size * output_seq_len * 1 * img_h * img_w\n",
        "        target_img_seq = target_img_seq.to(args.device)\n",
        "        # batch_size * output_seq_len\n",
        "        target_label_seq = target_label_seq.to(args.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        num_step_to_predict = target_label_seq.size(1)\n",
        "        forward = model(input_img_seq, num_step_to_predict)\n",
        "\n",
        "        pred = forward[:, -num_step_to_predict:]\n",
        "        loss = loss_func(pred.reshape(-1, 10), target_label_seq.reshape(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0: \n",
        "            print(\"Train: [{}/{} ({:.0f}%)], Loss: {:.5f}\".format(\n",
        "                batch_idx, len(mnist_train_loader), \n",
        "                100. * batch_idx / len(mnist_train_loader),\n",
        "                loss.item()\n",
        "            ))\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2178a45",
      "metadata": {
        "id": "e2178a45"
      },
      "source": [
        "## 3. Test \n",
        "- Once your model achieve descent training accuracy, you can run test to validate your model\n",
        "- You should achieve at least 93% Top1 Acc to get full credit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "60c090d4",
      "metadata": {
        "id": "60c090d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: [0/10000 (0%)] Top1 Acc: 99.999893, Top5 Acc: 99.999893\n",
            "Test: [500/10000 (5%)] Top1 Acc: 99.815561, Top5 Acc: 99.999991\n",
            "Test: [1000/10000 (10%)] Top1 Acc: 99.388247, Top5 Acc: 99.999995\n",
            "Test: [1500/10000 (15%)] Top1 Acc: 99.360210, Top5 Acc: 99.999997\n",
            "Test: [2000/10000 (20%)] Top1 Acc: 99.444136, Top5 Acc: 99.999998\n",
            "Test: [2500/10000 (25%)] Top1 Acc: 99.442764, Top5 Acc: 99.999998\n",
            "Test: [3000/10000 (30%)] Top1 Acc: 99.390558, Top5 Acc: 99.999998\n",
            "Test: [3500/10000 (35%)] Top1 Acc: 99.392276, Top5 Acc: 99.986262\n",
            "Test: [4000/10000 (40%)] Top1 Acc: 99.426434, Top5 Acc: 99.987892\n",
            "Test: [4500/10000 (45%)] Top1 Acc: 99.432990, Top5 Acc: 99.988998\n",
            "Test: [5000/10000 (50%)] Top1 Acc: 99.477752, Top5 Acc: 99.990147\n",
            "Test: [5500/10000 (55%)] Top1 Acc: 99.487705, Top5 Acc: 99.990941\n",
            "Test: [6000/10000 (60%)] Top1 Acc: 99.447164, Top5 Acc: 99.983672\n",
            "Test: [6500/10000 (65%)] Top1 Acc: 99.398112, Top5 Acc: 99.984899\n",
            "Test: [7000/10000 (70%)] Top1 Acc: 99.392319, Top5 Acc: 99.979024\n",
            "Test: [7500/10000 (75%)] Top1 Acc: 99.406154, Top5 Acc: 99.980417\n",
            "Test: [8000/10000 (80%)] Top1 Acc: 99.411853, Top5 Acc: 99.981691\n",
            "Test: [8500/10000 (85%)] Top1 Acc: 99.428550, Top5 Acc: 99.982658\n",
            "Test: [9000/10000 (90%)] Top1 Acc: 99.426468, Top5 Acc: 99.983579\n",
            "Test: [9500/10000 (95%)] Top1 Acc: 99.430871, Top5 Acc: 99.984477\n",
            "Shift 1, Test Top1 Acc: 99.439571, Test Top5 Acc: 99.439571\n",
            "Shift 2, Test Top1 Acc: 99.369005, Test Top5 Acc: 99.369005\n",
            "Shift 3, Test Top1 Acc: 99.567650, Test Top5 Acc: 99.567650\n",
            "Shift 4, Test Top1 Acc: 99.035608, Test Top5 Acc: 99.035608\n",
            "Shift 5, Test Top1 Acc: 99.747347, Test Top5 Acc: 99.747347\n"
          ]
        }
      ],
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    top1_acc_dict = {test_shift:{'sum_acc':0, 'count':0} for test_shift in args.test_shift_list}\n",
        "    top5_acc_dict = {test_shift:{'sum_acc':0, 'count':0} for test_shift in args.test_shift_list}\n",
        "    for batch_idx, (input_img_seq, target_img_seq, input_label_seq, target_label_seq, seq_shift) in enumerate(mnist_test_loader):\n",
        "        batch_size = input_img_seq.shape[0]\n",
        "        # batch_size * input_seq_len * 1 * img_h * img_w\n",
        "        input_img_seq = input_img_seq.to(args.device)\n",
        "        # batch_size * input_seq_len\n",
        "        input_label_seq = input_label_seq.to(args.device)\n",
        "        # batch_size * output_seq_len * 1 * img_h * img_w\n",
        "        target_img_seq = target_img_seq.to(args.device)\n",
        "        # batch_size * output_seq_len\n",
        "        target_label_seq = target_label_seq.to(args.device)\n",
        "        \n",
        "        total_pred = model(input_img_seq, args.target_seq_len)\n",
        "        pred = total_pred[:, args.input_seq_len:, :].reshape(-1, 10)\n",
        "\n",
        "        _, top_index = pred.topk(5, dim = -1)\n",
        "        correct_pred = top_index == target_label_seq.reshape(-1)[:,None]\n",
        "        top1_acc = correct_pred[:,0].float().reshape(batch_size, -1) * 100\n",
        "        top5_acc = correct_pred[:,:5].sum(dim = -1).float().reshape(batch_size, -1) * 100\n",
        "        for seq_shift_ele in torch.unique(seq_shift):\n",
        "            top1_acc_val = top1_acc[torch.where(seq_shift == seq_shift_ele)[0]].mean(dim = -1).sum()\n",
        "            top1_acc_count = torch.where(seq_shift == seq_shift_ele)[0].shape[0]\n",
        "            top1_acc_dict[seq_shift_ele.item()]['sum_acc'] += top1_acc_val.item()\n",
        "            top1_acc_dict[seq_shift_ele.item()]['count'] += top1_acc_count\n",
        "            \n",
        "            top5_acc_val = top5_acc[torch.where(seq_shift == seq_shift_ele)[0]].mean(dim = -1).sum()\n",
        "            top5_acc_count = torch.where(seq_shift == seq_shift_ele)[0].shape[0]\n",
        "            top5_acc_dict[seq_shift_ele.item()]['sum_acc'] += top5_acc_val.item()\n",
        "            top5_acc_dict[seq_shift_ele.item()]['count'] += top5_acc_count \n",
        "\n",
        "        total_top1_acc = np.mean(np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top1_acc_dict.items()]))\n",
        "        total_top5_acc = np.mean(np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top5_acc_dict.items()]))\n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Test: [{}/{} ({:.0f}%)] Top1 Acc: {:1f}, Top5 Acc: {:1f}'.format(\n",
        "                batch_idx * input_img_seq.shape[0], len(mnist_test_loader.dataset),\n",
        "                100. * batch_idx * input_img_seq.shape[0] / len(mnist_test_loader.dataset), total_top1_acc, total_top5_acc))\n",
        "        \n",
        "    top1_acc_each_shift = np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top1_acc_dict.items()])\n",
        "    top5_acc_each_shift = np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top1_acc_dict.items()])\n",
        "    for idx, (key, _) in enumerate(top1_acc_dict.items()):\n",
        "        print('Shift {}, Test Top1 Acc: {:1f}, Test Top5 Acc: {:1f}'.format(key, top1_acc_each_shift[idx], top5_acc_each_shift[idx]))\n",
        "test()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mnist_seq_prediction_release.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
