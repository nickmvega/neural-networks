{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c957f179",
      "metadata": {
        "id": "c957f179"
      },
      "source": [
        "## Part II: CNN-LSTM for Sequence Prediction\n",
        "### Introduction:\n",
        "\n",
        "- In this section, you will extend the CNN from section (1) to a hybrid CNN-LSTM model to predict the future elements of a sequence.\n",
        "- Instead of providing a single digit image to predict its category, you will be given a sequence of digit images. These sequences follow a pattern in that each consecutive image pair will be shifted by some constant amount. You will design a CNN-LSTM model to recognize those patterns from raw images and predict the future digits.\n",
        "- For instance, the input and target of the CNN-LSTM model can be the image squence whose categories are shown as below: \n",
        "            Input: 1,3,5,7,9,1   Target: 3,5,7  (shifted by 2)\n",
        "            Input: 2,6,0,4,8,2   Target: 6,0,4  (shifted by 4)\n",
        "where the input and target consists of 5 elements and 3 elements, respectively.\n",
        "- The training sequences are generated by varying shifts.  We will also include some unseen shifts in test sequences to validate the model's generalization ability.\n",
        "\n",
        "### Task:\n",
        "- You need to design the model and complete the training loop with Pytorch.\n",
        "- You need to achieve 93% averaged Top1 Acc on test data.\n",
        "- This experiment shares the same dataset with the first section. Once you prepare the data following the first section, you do not need to download extra content. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "14e6af01",
      "metadata": {
        "id": "14e6af01"
      },
      "outputs": [],
      "source": [
        "# The arguments of the experiment\n",
        "class Args:\n",
        "    def __init__(self):\n",
        "        # Based on the availablity of GPU, decide whether to run the experiment on cuda or cpu.\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # The random seed for the exp.\n",
        "        self.seed = 1\n",
        "        # The mini batch size of training and testing data. If you find you machines run very slow \n",
        "        # or experinece with OOM issue, you can set a smaller batch size\n",
        "        self.batch_size = 50\n",
        "        # The epochs of the exps. The referenced model achieve over 95% test accuracy after 1 epoch.\n",
        "        self.epochs = 1\n",
        "        # The learning rate of the SGD optimizer\n",
        "        self.lr = 0.1\n",
        "        # The momentum of SGD optimizer\n",
        "        self.momentum = 0.5\n",
        "        # how many iterations to display the training stats\n",
        "        self.log_interval = 10\n",
        "        # The height of input image\n",
        "        self.img_h = 28\n",
        "        # The width of the input image\n",
        "        self.img_w = 28\n",
        "        # The length of input sequence\n",
        "        self.input_seq_len = 5\n",
        "        # The lenght of the sequence to predict\n",
        "        self.target_seq_len = 2\n",
        "        # The list to sample shift to generate the training sequence.\n",
        "        self.train_shift_list = [1,2,4,5]\n",
        "        # The list to sample shift to generate the testing sequence. \n",
        "        self.test_shift_list = [1,2,3,4,5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "79b9552c-9f53-4a5e-97d9-3b3c8c5c817a",
      "metadata": {
        "id": "79b9552c-9f53-4a5e-97d9-3b3c8c5c817a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x76fdfa26a750>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pytorch mnist cnn + lstm\n",
        "# Load necessary library\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Dataset \n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt \n",
        "args = Args()\n",
        "torch.manual_seed(args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d87a29",
      "metadata": {
        "id": "71d87a29"
      },
      "source": [
        "### 0. The dataloader\n",
        "- Load the data from csv file\n",
        "- Generate the input and target image sequences spaced by constant distance sampled from the predefined shift list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "713c2177-153d-446b-ae15-9489c0bba936",
      "metadata": {
        "id": "713c2177-153d-446b-ae15-9489c0bba936"
      },
      "outputs": [],
      "source": [
        "# The dataset to generated training and testing sequence\n",
        "class MNIST_SEQ_DATASET(Dataset):\n",
        "    def __init__(self, csv_path, height, width, input_len, output_len, seq_shift, transform=None):\n",
        "        \"\"\"\n",
        "        Custom dataset example for reading data from csv\n",
        "\n",
        "        Args:\n",
        "            csv_path (string): path to csv file\n",
        "            height (int): image height\n",
        "            width (int): image width\n",
        "            transform: pytorch transforms for transforms and tensor conversion\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_path)\n",
        "        self.labels = np.asarray(self.data.iloc[:, 0])\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.input_len = input_len\n",
        "        self.output_len = output_len\n",
        "        self.transform = transform\n",
        "        self.seq_shift = seq_shift\n",
        "        unique_label_array = np.unique(self.labels)\n",
        "        self.label_data_id_dict = {}\n",
        "        for unique_label in unique_label_array:\n",
        "            self.label_data_id_dict[unique_label] = np.where(self.labels == unique_label)[0]   \n",
        "        \n",
        "    def get_single_image(self, index):\n",
        "        single_image_label = self.labels[index]\n",
        "        # Read each 784 pixels and reshape the 1D array ([784]) to 2D array ([28,28])\n",
        "        img_as_np = np.asarray(self.data.iloc[index][1:]).reshape(28, 28).astype('uint8')\n",
        "        # Convert image from numpy array to PIL image, mode 'L' is for grayscale\n",
        "        img_as_img = Image.fromarray(img_as_np)\n",
        "        img_as_img = img_as_img.convert('L')\n",
        "        # Transform image to tensor\n",
        "        if self.transform is not None:\n",
        "            img_as_tensor = self.transform(img_as_img)\n",
        "        # Return image and the label\n",
        "        return (img_as_tensor, single_image_label)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Randomly sample the shift from predefined shift list\n",
        "        seq_shift = np.random.choice(self.seq_shift)\n",
        "        # Randomly select one category as leading digit\n",
        "        start_idx = np.random.choice(10)\n",
        "        # The sequence with following digits\n",
        "        seq_digit = np.arange(start_idx, start_idx + seq_shift * (self.input_len + self.output_len), seq_shift)\n",
        "        # Modulo opeartion over the digit sequence\n",
        "        seq_digit = seq_digit % 10\n",
        "        img_seq = []\n",
        "        label_seq = []\n",
        "        # Collect the images for each digit\n",
        "        for digit in seq_digit:\n",
        "            data_id = np.random.choice(self.label_data_id_dict[digit])\n",
        "            img, label = self.get_single_image(data_id)\n",
        "            img_seq.append(img)\n",
        "            label_seq.append(label)\n",
        "        # Return image and the label\n",
        "        input_img_seq = img_seq[:self.input_len]\n",
        "        input_label_seq = label_seq[:self.input_len]\n",
        "        target_img_seq = img_seq[self.input_len:]\n",
        "        target_label_seq = label_seq[self.input_len:]\n",
        "        return torch.stack(input_img_seq), torch.stack(target_img_seq), \\\n",
        "                torch.from_numpy(np.stack(input_label_seq)), \\\n",
        "                torch.from_numpy(np.stack(target_label_seq)), \\\n",
        "                seq_shift\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d9e8b05a",
      "metadata": {
        "id": "d9e8b05a"
      },
      "outputs": [],
      "source": [
        "# Instantiate the dataset which is then wrapperd by the DataLoader for effective prefecting\n",
        "transformations = transforms.Compose([transforms.ToTensor()])\n",
        "mnist_train = \\\n",
        "    MNIST_SEQ_DATASET('./mnist_train.csv',\n",
        "                             args.img_h, args.img_w, args.input_seq_len, args.target_seq_len,\n",
        "                             args.test_shift_list,\n",
        "                             transformations)\n",
        "\n",
        "mnist_test = \\\n",
        "    MNIST_SEQ_DATASET('./mnist_test.csv',\n",
        "                             args.img_h, args.img_w, args.input_seq_len, args.target_seq_len,\n",
        "                             args.test_shift_list,\n",
        "                             transformations)\n",
        "\n",
        "mnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                                    batch_size=args.batch_size,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
        "                                                    batch_size=args.batch_size,\n",
        "                                                    shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "354edd11",
      "metadata": {
        "id": "354edd11",
        "outputId": "3590efd7-a726-4deb-bf4c-89e9bb3ed412"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display the input sequence and target sequence\n",
        "input_img_seq, target_img_seq, input_label_seq, target_label_seq, seq_shift = mnist_train[0]\n",
        "img_to_disp = input_img_seq.permute(1,2,0,3).reshape(args.img_h,-1,args.img_w)\n",
        "input_img_seq = img_to_disp.reshape(args.img_h, -1)\n",
        "img_to_disp = target_img_seq.permute(1,2,0,3).reshape(args.img_h,-1,args.img_w)\n",
        "target_img_seq = img_to_disp.reshape(args.img_h, -1)\n",
        "plt.imshow(input_img_seq,  cmap=\"gray\")\n",
        "plt.title('input sequence shifed by {}'.format(seq_shift))\n",
        "plt.show()\n",
        "plt.imshow(target_img_seq, cmap=\"gray\")\n",
        "plt.title('target sequence shifed by {}'.format(seq_shift))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd654469",
      "metadata": {
        "id": "cd654469"
      },
      "source": [
        "### 1. (TODO) The CNN-LSTM Model [20 points]\n",
        "- Complete the following section to create a CNN-LSTM model for the sequence prediction problem. \n",
        "- You can borrow the CNN design from previous section as the CNN encodes the categorical features of the image\n",
        "- The CNN-LSTM should consist of the three modules: \n",
        "    - CNN for extracting visual features to a single feature vector\n",
        "    - LSTM taking as input the sequence of feature vectors from CNN and producing a hidden state suitable to predict the next element\n",
        "    - A decoder to convert the LSTM hidden state to a categorical prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "879a59ad",
      "metadata": {
        "id": "879a59ad"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"Custom CNN model to extract visual features from input image\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\" Define and instantiate your layers\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(800, 128)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\" \n",
        "        Run forward pass on input image X\n",
        "        \n",
        "        Args:\n",
        "            x: torch tensor of input image, \n",
        "                with shape of [batch_size, 1, img_h, img_w]\n",
        "        \n",
        "        Return:\n",
        "            out: torch tensor of feature vector computed on input image, \n",
        "                with shape of [batch_size, latent_dim]\n",
        "         \n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        \n",
        "        x = x.view(-1, 800)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class CNN_LSTM(nn.Module):\n",
        "    \"\"\" Custom CNN-LSTM model for sequence prediction problem \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\" Define and instantiate your layers\"\"\"\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        # YOUR CODE HERE\n",
        "        self.cnn = CNN()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=10, hidden_size=128, num_layers=1, batch_first=True)\n",
        "\n",
        "        self.decoder = nn.Linear(in_features=128, out_features=10)\n",
        "\n",
        "    def forward(self, x, num_step_to_predict):\n",
        "        \"\"\" \n",
        "        Run forward pass on image squence x and predict the future digits\n",
        "        \n",
        "        Args:\n",
        "            x : torch tensor of input image sequence, \n",
        "                    with shape of [batch_size, input_time_step, 1, img_h, img_w]\n",
        "            num_step_to_predict: an interger on how many steps to predict. \n",
        "            \n",
        "        Returns:\n",
        "            output: torch tensor of predicted categorical distribution  \n",
        "                    for the ENTIRE sequence, including input and predicted sequence, \n",
        "                    with shape of [batch_size, input_time_step + num_step_to_predict, 10].\n",
        "                    Noted the output from i step is the prediction for 1+1 step. \n",
        "            \n",
        "        \"\"\"\n",
        "        batch_size, input_time_step = x.size(0), x.size(1)\n",
        "\n",
        "        x = x.view(batch_size * input_time_step, 1, x.size(3), x.size(4))\n",
        "\n",
        "        cnn = self.cnn(x)\n",
        "        cnn = cnn.view(batch_size, input_time_step, -1)\n",
        "\n",
        "        output_lstm, (h_n, c_n) = self.lstm(cnn)\n",
        "        output_decoder = self.decoder(output_lstm)\n",
        "\n",
        "        curr_output = output_lstm[:, -1:, :]\n",
        "        curr_decoder = self.decoder(curr_output)\n",
        "\n",
        "        pred_i = []\n",
        "        for _ in range(num_step_to_predict):\n",
        "            predicted_seq, (h_n, c_n) = self.lstm(curr_decoder, (h_n, c_n))\n",
        "            curr_output = predicted_seq\n",
        "            curr_decoder = self.decoder(predicted_seq)\n",
        "            pred_i.append(curr_decoder)\n",
        "\n",
        "        return torch.cat([output_decoder, torch.cat(pred_i, dim=1)], dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36ee3154",
      "metadata": {
        "id": "36ee3154"
      },
      "source": [
        "### 2. (TODO) The Training Loop [15 points]\n",
        "- Instantiate the model and optimizer\n",
        "- Select proper loss function for this task\n",
        "- Complete the training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "064084e1-ac41-4e84-a666-a3446b69fe9a",
      "metadata": {
        "id": "064084e1-ac41-4e84-a666-a3446b69fe9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: [0/1200 (0%)], Loss: 2.30615\n",
            "Train: [10/1200 (1%)], Loss: 2.31083\n",
            "Train: [20/1200 (2%)], Loss: 2.29843\n",
            "Train: [30/1200 (2%)], Loss: 2.30016\n",
            "Train: [40/1200 (3%)], Loss: 2.30068\n",
            "Train: [50/1200 (4%)], Loss: 2.29457\n",
            "Train: [60/1200 (5%)], Loss: 2.30096\n",
            "Train: [70/1200 (6%)], Loss: 2.28424\n",
            "Train: [80/1200 (7%)], Loss: 2.27742\n",
            "Train: [90/1200 (8%)], Loss: 2.27689\n",
            "Train: [100/1200 (8%)], Loss: 2.26013\n",
            "Train: [110/1200 (9%)], Loss: 2.25123\n",
            "Train: [120/1200 (10%)], Loss: 2.20155\n",
            "Train: [130/1200 (11%)], Loss: 2.17786\n",
            "Train: [140/1200 (12%)], Loss: 2.20059\n",
            "Train: [150/1200 (12%)], Loss: 2.15181\n",
            "Train: [160/1200 (13%)], Loss: 2.08841\n",
            "Train: [170/1200 (14%)], Loss: 2.03716\n",
            "Train: [180/1200 (15%)], Loss: 2.06591\n",
            "Train: [190/1200 (16%)], Loss: 2.04921\n",
            "Train: [200/1200 (17%)], Loss: 1.99544\n",
            "Train: [210/1200 (18%)], Loss: 2.02255\n",
            "Train: [220/1200 (18%)], Loss: 1.95704\n",
            "Train: [230/1200 (19%)], Loss: 2.03091\n",
            "Train: [240/1200 (20%)], Loss: 1.98787\n",
            "Train: [250/1200 (21%)], Loss: 1.95672\n",
            "Train: [260/1200 (22%)], Loss: 1.97461\n",
            "Train: [270/1200 (22%)], Loss: 1.93624\n",
            "Train: [280/1200 (23%)], Loss: 1.86942\n",
            "Train: [290/1200 (24%)], Loss: 1.83436\n",
            "Train: [300/1200 (25%)], Loss: 1.82866\n",
            "Train: [310/1200 (26%)], Loss: 1.88963\n",
            "Train: [320/1200 (27%)], Loss: 1.74349\n",
            "Train: [330/1200 (28%)], Loss: 1.66341\n",
            "Train: [340/1200 (28%)], Loss: 1.69234\n",
            "Train: [350/1200 (29%)], Loss: 1.64211\n",
            "Train: [360/1200 (30%)], Loss: 1.59265\n",
            "Train: [370/1200 (31%)], Loss: 1.59335\n",
            "Train: [380/1200 (32%)], Loss: 1.49057\n",
            "Train: [390/1200 (32%)], Loss: 1.45287\n",
            "Train: [400/1200 (33%)], Loss: 1.33636\n",
            "Train: [410/1200 (34%)], Loss: 1.39935\n",
            "Train: [420/1200 (35%)], Loss: 1.33103\n",
            "Train: [430/1200 (36%)], Loss: 1.29574\n",
            "Train: [440/1200 (37%)], Loss: 1.02892\n",
            "Train: [450/1200 (38%)], Loss: 1.11798\n",
            "Train: [460/1200 (38%)], Loss: 1.15686\n",
            "Train: [470/1200 (39%)], Loss: 0.92502\n",
            "Train: [480/1200 (40%)], Loss: 0.89512\n",
            "Train: [490/1200 (41%)], Loss: 0.80357\n",
            "Train: [500/1200 (42%)], Loss: 0.81035\n",
            "Train: [510/1200 (42%)], Loss: 0.72706\n",
            "Train: [520/1200 (43%)], Loss: 0.73859\n",
            "Train: [530/1200 (44%)], Loss: 0.66228\n",
            "Train: [540/1200 (45%)], Loss: 0.63802\n",
            "Train: [550/1200 (46%)], Loss: 0.49889\n",
            "Train: [560/1200 (47%)], Loss: 0.49193\n",
            "Train: [570/1200 (48%)], Loss: 0.41958\n",
            "Train: [580/1200 (48%)], Loss: 0.52264\n",
            "Train: [590/1200 (49%)], Loss: 0.33860\n",
            "Train: [600/1200 (50%)], Loss: 0.41657\n",
            "Train: [610/1200 (51%)], Loss: 0.37673\n",
            "Train: [620/1200 (52%)], Loss: 0.30799\n",
            "Train: [630/1200 (52%)], Loss: 0.25139\n",
            "Train: [640/1200 (53%)], Loss: 0.39502\n",
            "Train: [650/1200 (54%)], Loss: 0.21545\n",
            "Train: [660/1200 (55%)], Loss: 0.17090\n",
            "Train: [670/1200 (56%)], Loss: 0.29491\n",
            "Train: [680/1200 (57%)], Loss: 0.29712\n",
            "Train: [690/1200 (58%)], Loss: 0.19845\n",
            "Train: [700/1200 (58%)], Loss: 0.21914\n",
            "Train: [710/1200 (59%)], Loss: 0.27029\n",
            "Train: [720/1200 (60%)], Loss: 0.16300\n",
            "Train: [730/1200 (61%)], Loss: 0.11062\n",
            "Train: [740/1200 (62%)], Loss: 0.16642\n",
            "Train: [750/1200 (62%)], Loss: 0.10163\n",
            "Train: [760/1200 (63%)], Loss: 0.29820\n",
            "Train: [770/1200 (64%)], Loss: 0.12789\n",
            "Train: [780/1200 (65%)], Loss: 0.08948\n",
            "Train: [790/1200 (66%)], Loss: 0.07030\n",
            "Train: [800/1200 (67%)], Loss: 0.09496\n",
            "Train: [810/1200 (68%)], Loss: 0.07405\n",
            "Train: [820/1200 (68%)], Loss: 0.08357\n",
            "Train: [830/1200 (69%)], Loss: 0.11427\n",
            "Train: [840/1200 (70%)], Loss: 0.06177\n",
            "Train: [850/1200 (71%)], Loss: 0.09382\n",
            "Train: [860/1200 (72%)], Loss: 0.04864\n",
            "Train: [870/1200 (72%)], Loss: 0.07942\n",
            "Train: [880/1200 (73%)], Loss: 0.10953\n",
            "Train: [890/1200 (74%)], Loss: 0.03830\n",
            "Train: [900/1200 (75%)], Loss: 0.04839\n",
            "Train: [910/1200 (76%)], Loss: 0.11971\n",
            "Train: [920/1200 (77%)], Loss: 0.04011\n",
            "Train: [930/1200 (78%)], Loss: 0.06523\n",
            "Train: [940/1200 (78%)], Loss: 0.08989\n",
            "Train: [950/1200 (79%)], Loss: 0.03961\n",
            "Train: [960/1200 (80%)], Loss: 0.02518\n",
            "Train: [970/1200 (81%)], Loss: 0.17960\n",
            "Train: [980/1200 (82%)], Loss: 0.03748\n",
            "Train: [990/1200 (82%)], Loss: 0.06811\n",
            "Train: [1000/1200 (83%)], Loss: 0.04433\n",
            "Train: [1010/1200 (84%)], Loss: 0.03825\n",
            "Train: [1020/1200 (85%)], Loss: 0.04898\n",
            "Train: [1030/1200 (86%)], Loss: 0.02903\n",
            "Train: [1040/1200 (87%)], Loss: 0.01605\n",
            "Train: [1050/1200 (88%)], Loss: 0.05972\n",
            "Train: [1060/1200 (88%)], Loss: 0.04935\n",
            "Train: [1070/1200 (89%)], Loss: 0.02090\n",
            "Train: [1080/1200 (90%)], Loss: 0.02933\n",
            "Train: [1090/1200 (91%)], Loss: 0.04073\n",
            "Train: [1100/1200 (92%)], Loss: 0.03343\n",
            "Train: [1110/1200 (92%)], Loss: 0.03368\n",
            "Train: [1120/1200 (93%)], Loss: 0.02223\n",
            "Train: [1130/1200 (94%)], Loss: 0.05202\n",
            "Train: [1140/1200 (95%)], Loss: 0.02214\n",
            "Train: [1150/1200 (96%)], Loss: 0.03422\n",
            "Train: [1160/1200 (97%)], Loss: 0.01793\n",
            "Train: [1170/1200 (98%)], Loss: 0.02741\n",
            "Train: [1180/1200 (98%)], Loss: 0.04375\n",
            "Train: [1190/1200 (99%)], Loss: 0.03760\n"
          ]
        }
      ],
      "source": [
        "model = CNN_LSTM()\n",
        "model = model.to(args.device)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (input_img_seq, target_img_seq, input_label_seq, target_label_seq, seq_shift) in enumerate(mnist_train_loader):\n",
        "        # batch_size * input_seq_len * 1 * img_h * img_w\n",
        "        input_img_seq = input_img_seq.to(args.device)\n",
        "        # batch_size * input_seq_len\n",
        "        input_label_seq = input_label_seq.to(args.device)\n",
        "        # batch_size * output_seq_len * 1 * img_h * img_w\n",
        "        target_img_seq = target_img_seq.to(args.device)\n",
        "        # batch_size * output_seq_len\n",
        "        target_label_seq = target_label_seq.to(args.device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        num_step_to_predict = target_label_seq.size(1)\n",
        "        forward = model(input_img_seq, num_step_to_predict)\n",
        "\n",
        "        pred = forward[:,:-1][:,-1 * args.target_seq_len:, :].reshape(-1,10)\n",
        "        loss = loss_func(pred, target_label_seq.reshape(-1))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % args.log_interval == 0: \n",
        "            print(\"Train: [{}/{} ({:.0f}%)], Loss: {:.5f}\".format(\n",
        "                batch_idx, len(mnist_train_loader), \n",
        "                100. * batch_idx / len(mnist_train_loader),\n",
        "                loss.item()\n",
        "            ))\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    train(epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2178a45",
      "metadata": {
        "id": "e2178a45"
      },
      "source": [
        "## 3. Test \n",
        "- Once your model achieve descent training accuracy, you can run test to validate your model\n",
        "- You should achieve at least 93% Top1 Acc to get full credit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "60c090d4",
      "metadata": {
        "id": "60c090d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test: [0/10000 (0%)] Top1 Acc: 98.578317, Top5 Acc: 99.999885\n",
            "Test: [500/10000 (5%)] Top1 Acc: 97.919802, Top5 Acc: 99.911495\n",
            "Test: [1000/10000 (10%)] Top1 Acc: 98.293278, Top5 Acc: 99.950734\n",
            "Test: [1500/10000 (15%)] Top1 Acc: 98.299747, Top5 Acc: 99.967210\n",
            "Test: [2000/10000 (20%)] Top1 Acc: 98.459258, Top5 Acc: 99.974745\n",
            "Test: [2500/10000 (25%)] Top1 Acc: 98.548127, Top5 Acc: 99.959675\n",
            "Test: [3000/10000 (30%)] Top1 Acc: 98.505839, Top5 Acc: 99.966498\n",
            "Test: [3500/10000 (35%)] Top1 Acc: 98.567269, Top5 Acc: 99.970281\n",
            "Test: [4000/10000 (40%)] Top1 Acc: 98.585493, Top5 Acc: 99.974226\n",
            "Test: [4500/10000 (45%)] Top1 Acc: 98.595340, Top5 Acc: 99.976824\n",
            "Test: [5000/10000 (50%)] Top1 Acc: 98.629281, Top5 Acc: 99.979231\n",
            "Test: [5500/10000 (55%)] Top1 Acc: 98.602533, Top5 Acc: 99.972549\n",
            "Test: [6000/10000 (60%)] Top1 Acc: 98.639817, Top5 Acc: 99.966768\n",
            "Test: [6500/10000 (65%)] Top1 Acc: 98.639797, Top5 Acc: 99.961530\n",
            "Test: [7000/10000 (70%)] Top1 Acc: 98.624222, Top5 Acc: 99.957564\n",
            "Test: [7500/10000 (75%)] Top1 Acc: 98.618451, Top5 Acc: 99.947025\n",
            "Test: [8000/10000 (80%)] Top1 Acc: 98.622205, Top5 Acc: 99.950361\n",
            "Test: [8500/10000 (85%)] Top1 Acc: 98.642467, Top5 Acc: 99.953211\n",
            "Test: [9000/10000 (90%)] Top1 Acc: 98.592509, Top5 Acc: 99.955941\n",
            "Test: [9500/10000 (95%)] Top1 Acc: 98.559601, Top5 Acc: 99.958133\n",
            "Shift 1, Test Top1 Acc: 98.962025, Test Top5 Acc: 98.962025\n",
            "Shift 2, Test Top1 Acc: 98.075072, Test Top5 Acc: 98.075072\n",
            "Shift 3, Test Top1 Acc: 97.658610, Test Top5 Acc: 97.658610\n",
            "Shift 4, Test Top1 Acc: 98.643216, Test Top5 Acc: 98.643216\n",
            "Shift 5, Test Top1 Acc: 99.365804, Test Top5 Acc: 99.365804\n"
          ]
        }
      ],
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    top1_acc_dict = {test_shift:{'sum_acc':0, 'count':0} for test_shift in args.test_shift_list}\n",
        "    top5_acc_dict = {test_shift:{'sum_acc':0, 'count':0} for test_shift in args.test_shift_list}\n",
        "    for batch_idx, (input_img_seq, target_img_seq, input_label_seq, target_label_seq, seq_shift) in enumerate(mnist_test_loader):\n",
        "        batch_size = input_img_seq.shape[0]\n",
        "        # batch_size * input_seq_len * 1 * img_h * img_w\n",
        "        input_img_seq = input_img_seq.to(args.device)\n",
        "        # batch_size * input_seq_len\n",
        "        input_label_seq = input_label_seq.to(args.device)\n",
        "        # batch_size * output_seq_len * 1 * img_h * img_w\n",
        "        target_img_seq = target_img_seq.to(args.device)\n",
        "        # batch_size * output_seq_len\n",
        "        target_label_seq = target_label_seq.to(args.device)\n",
        "        \n",
        "        total_pred = model(input_img_seq, args.target_seq_len)\n",
        "        pred = total_pred[:,:-1][:,-1 * args.target_seq_len:].reshape(-1,10)\n",
        "\n",
        "        _, top_index = pred.topk(5, dim = -1)\n",
        "        correct_pred = top_index == target_label_seq.reshape(-1)[:,None]\n",
        "        top1_acc = correct_pred[:,0].float().reshape(batch_size, -1) * 100\n",
        "        top5_acc = correct_pred[:,:5].sum(dim = -1).float().reshape(batch_size, -1) * 100\n",
        "        for seq_shift_ele in torch.unique(seq_shift):\n",
        "            top1_acc_val = top1_acc[torch.where(seq_shift == seq_shift_ele)[0]].mean(dim = -1).sum()\n",
        "            top1_acc_count = torch.where(seq_shift == seq_shift_ele)[0].shape[0]\n",
        "            top1_acc_dict[seq_shift_ele.item()]['sum_acc'] += top1_acc_val.item()\n",
        "            top1_acc_dict[seq_shift_ele.item()]['count'] += top1_acc_count\n",
        "            \n",
        "            top5_acc_val = top5_acc[torch.where(seq_shift == seq_shift_ele)[0]].mean(dim = -1).sum()\n",
        "            top5_acc_count = torch.where(seq_shift == seq_shift_ele)[0].shape[0]\n",
        "            top5_acc_dict[seq_shift_ele.item()]['sum_acc'] += top5_acc_val.item()\n",
        "            top5_acc_dict[seq_shift_ele.item()]['count'] += top5_acc_count \n",
        "\n",
        "        total_top1_acc = np.mean(np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top1_acc_dict.items()]))\n",
        "        total_top5_acc = np.mean(np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top5_acc_dict.items()]))\n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Test: [{}/{} ({:.0f}%)] Top1 Acc: {:1f}, Top5 Acc: {:1f}'.format(\n",
        "                batch_idx * input_img_seq.shape[0], len(mnist_test_loader.dataset),\n",
        "                100. * batch_idx * input_img_seq.shape[0] / len(mnist_test_loader.dataset), total_top1_acc, total_top5_acc))\n",
        "        \n",
        "    top1_acc_each_shift = np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top1_acc_dict.items()])\n",
        "    top5_acc_each_shift = np.stack([val['sum_acc'] / (val['count'] + 1e-5) for key, val in top1_acc_dict.items()])\n",
        "    for idx, (key, _) in enumerate(top1_acc_dict.items()):\n",
        "        print('Shift {}, Test Top1 Acc: {:1f}, Test Top5 Acc: {:1f}'.format(key, top1_acc_each_shift[idx], top5_acc_each_shift[idx]))\n",
        "test()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mnist_seq_prediction_release.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
